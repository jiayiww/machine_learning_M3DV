{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 2\n",
    "NUM_MODELS = 5\n",
    "\n",
    "path = 'sjtu-m3dv-medical-3d-voxel-classification'\n",
    "train_path = path+'/train_val'\n",
    "test_path = path+'/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像采样压缩\n",
    "def compress(org):\n",
    "    res = np.zeros((32,32,32))\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            for k in range(32):\n",
    "                res[i,j,k] = (org[3*i:3*i+2, 3*j:3*j+2, 3*k:3*k+2].sum()) / 27\n",
    "    return res\n",
    "# 生成随机数\n",
    "def random_list(l,h,n):\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        res.append(random.randint(l,h))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开训练集结果文件\n",
    "train_res = []\n",
    "with open(path+'/train_val.csv') as f:\n",
    "    next(f)\n",
    "    f_csv = csv.reader(f)\n",
    "    for row in f_csv:\n",
    "        train_res.append(float(row[1]))\n",
    "f.close()\n",
    "# 打开训练集数据文件\n",
    "train_npz = os.listdir(train_path)\n",
    "train_num = len(train_npz)\n",
    "\n",
    "def open_train_seg():\n",
    "    train_voxel = []\n",
    "    train_seg = []\n",
    "    for i in range(train_num):\n",
    "        file = np.load(train_path+'/'+train_npz[i])\n",
    "        seg = file['seg'].astype(np.float)*270\n",
    "        t = random_list(0,4,3)+random_list(0,3,3)\n",
    "        seg = compress(seg[t[0]:t[0]+96,t[1]:t[1]+96,t[2]:t[2]+96])\n",
    "        seg = np.rot90(seg,t[3],(0,1))\n",
    "        seg = np.rot90(seg,t[4],(0,2))\n",
    "        seg = np.rot90(seg,t[5],(1,2))\n",
    "        train_seg.append((seg,train_res[i]))\n",
    "    # 加载训练集 \n",
    "    train_seg_loader = data.DataLoader(train_seg,\n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       shuffle=True,\n",
    "                                       drop_last=True) \n",
    "    return train_seg_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开测试集文件\n",
    "test_npz = os.listdir(test_path)\n",
    "test_num = len(test_npz)\n",
    "def open_test_seg():\n",
    "    test_seg = []\n",
    "    for i in range(test_num):\n",
    "        file = np.load(test_path+'/'+test_npz[i])\n",
    "        seg = file['seg'].astype(np.float)*270\n",
    "        t = random_list(0,4,3)+random_list(0,3,3)\n",
    "        seg = compress(seg[t[0]:t[0]+96,t[1]:t[1]+96,t[2]:t[2]+96])\n",
    "        seg = np.rot90(seg,t[3],(0,1))\n",
    "        seg = np.rot90(seg,t[4],(0,2))\n",
    "        seg = np.rot90(seg,t[5],(1,2))\n",
    "        test_seg.append(seg)\n",
    "    # 加载测试集\n",
    "    test_seg_loader = data.DataLoader(test_seg, \n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=True) \n",
    "    return(test_seg_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Sequential):\n",
    "    def __init__(self,in_channel,growth_rate,bn_size,drop_rate): \n",
    "        super(DenseLayer,self).__init__()\n",
    "        self.add_module('norm1',nn.BatchNorm3d(in_channel)),\n",
    "        self.add_module('relu1',nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1',nn.Conv3d(in_channel,bn_size*growth_rate,\n",
    "                                          kernel_size=1,stride=1,bias=False)),\n",
    "        self.add_module('norm2',nn.BatchNorm3d(bn_size*growth_rate)),\n",
    "        self.add_module('relu2',nn.ReLU(inplace=True))\n",
    "        self.add_module('conv2',nn.Conv3d(bn_size*growth_rate,growth_rate,\n",
    "                                          kernel_size=3,stride=1,padding=1,bias=False))\n",
    "        self.drop_rate = drop_rate\n",
    "    def forward(self,x):\n",
    "        new_feature = super(DenseLayer,self).forward(x)\n",
    "        if(self.drop_rate>0):\n",
    "            new_feature = F.dropout3d(new_feature,p=self.drop_rate,training=self.training)\n",
    "        return torch.cat([x,new_feature],1) \n",
    "\n",
    "class DenseBlock(nn.Sequential):\n",
    "    def __init__(self,layer_num,in_channel,bn_size,growth_rate,drop_rate):\n",
    "        super(DenseBlock,self).__init__()\n",
    "        for i in range(layer_num):\n",
    "            layer = DenseLayer(in_channel+i*growth_rate,growth_rate,bn_size,drop_rate)\n",
    "            self.add_module('denselayer%d'%(i+1),layer)\n",
    "\n",
    "class Transition(nn.Sequential):\n",
    "    def __init__(self,in_channel,zip_ratio=0.5):\n",
    "        super(Transition,self).__init__()\n",
    "        self.add_module('norm',nn.BatchNorm3d(in_channel))\n",
    "        self.add_module('relu',nn.ReLU(inplace=True))\n",
    "        self.add_module('conv',nn.Conv3d(in_channel,int(in_channel*zip_ratio),\n",
    "                                         kernel_size=1,stride=1,bias=False))\n",
    "        self.add_module('pool',nn.AvgPool3d(kernel_size=2,stride=2))\n",
    "\n",
    "#卷积池化层\n",
    "def FeatureLayer(in_channel,out_channel):\n",
    "    layer = nn.Sequential(\n",
    "            nn.Conv3d(in_channel,out_channel,\n",
    "                      kernel_size=3,stride=1,padding=3,bias=False),\n",
    "            nn.BatchNorm3d(num_features=out_channel), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool3d(kernel_size=3,stride=2,padding=1))\n",
    "    return layer\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,growth_rate=32,block_config=(4,4,4),init_channel_num=64,\n",
    "                 bn_size=4,drop_rate=0):\n",
    "        super(DenseNet,self).__init__()\n",
    "        self.feature_layer = FeatureLayer(1,init_channel_num)\n",
    "        channel_num = init_channel_num\n",
    "        for i,layer_num in enumerate(block_config):\n",
    "            block = DenseBlock(layer_num=layer_num,in_channel=channel_num,\n",
    "                               bn_size=bn_size,growth_rate=growth_rate,\n",
    "                               drop_rate=drop_rate)\n",
    "            self.feature_layer.add_module('denseblock%d'%(i+1),block)\n",
    "            channel_num = channel_num + layer_num*growth_rate\n",
    "            if(i!=len(block_config)-1):\n",
    "                trans = Transition(channel_num,0.5)\n",
    "                self.feature_layer.add_module('transition%d'%(i+1),trans)\n",
    "                channel_num = int(0.5*channel_num)\n",
    "        self.feature_layer.add_module('norm5',nn.BatchNorm3d(channel_num))\n",
    "        self.feature_layer.add_module('relu5',nn.ReLU(inplace=True))\n",
    "        self.feature_layer.add_module('avgpool5',\n",
    "                                      nn.AvgPool3d(kernel_size=3,stride=2))\n",
    "        self.classifier = nn.Linear(channel_num,1) \n",
    "        self.sigmoid = torch.sigmoid\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.feature_layer(x)\n",
    "        out = features.view(len(x),-1)\n",
    "        out = self.classifier(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = out.view(len(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg = DenseNet(drop_rate=0.3)\n",
    "\n",
    "optimizer_seg = torch.optim.SGD(model_voxel.parameters(),lr=0.01)\n",
    "criterion_seg = nn.MultiLabelSoftMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练 \n",
    "for i in range(NUM_MODELS):\n",
    "    model_seg.train()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_seg_loader = open_train_seg()\n",
    "        optimizer_seg.zero_grad()\n",
    "        for images,labels in train_seg_loader:\n",
    "            images = images.view(BATCH_SIZE,1,32,32,32)\n",
    "            outputs = model_seg(images.float())\n",
    "            labels = labels.view(BATCH_SIZE,1)\n",
    "            outputs = outputs.view(BATCH_SIZE,1)\n",
    "            loss = criterion_seg(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer_seg.step()\n",
    "    name = 'try_3_seg_model_' + str(i+1) + '.pkl'\n",
    "    torch.save(model_seg,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "model = torch.load('try_0_voxel_model.pkl')\n",
    "pred = []\n",
    "for i in range(NUM_MODELS):\n",
    "    name = 'try_3_seg_model_' + str(i+1) + '.pkl'\n",
    "    model = torch.load('name')\n",
    "    for j in range(NUM_MODELS):\n",
    "        test_seg_loader = open_test_seg()\n",
    "        model_seg.eval()\n",
    "        pred_seg = torch.ones(0)\n",
    "        for images in test_seg_loader:\n",
    "            images = images.view(BATCH_SIZE,1,32,32,32)\n",
    "            with torch.no_grad():\n",
    "                outputs = model_seg(images.float())\n",
    "            pred_seg = torch.cat([pred_seg,outputs]) \n",
    "            \n",
    "        pred.append(pred_seg)\n",
    "\n",
    "out = pred[0]\n",
    "for i in range(1,len(pred)):\n",
    "    out = out + pred[i]\n",
    "    \n",
    "out = out/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('try_3.csv', out, delimiter = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
